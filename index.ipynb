{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7dcb96",
   "metadata": {},
   "source": [
    "# Chargement des fichiers sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afa08c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargé : Warhammer 4 - Livre de base.pdf (67641992 caractères) .pdf)\n",
      "Conversion du PDF Warhammer 4 - Livre de base.pdf en TXT...\n",
      "Fichier TXT créé : Warhammer 4 - Livre de base.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Import Files \n",
    "def file_loader(folder):\n",
    "    files = []\n",
    "    for i, file_name in enumerate(os.listdir(folder)):\n",
    "        file_path = os.path.join(folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            extension = os.path.splitext(file_name)[1].lower()\n",
    "            with open(file_path, 'r', encoding='latin-1') as f:\n",
    "                files.append({\n",
    "                    'name': file_name,\n",
    "                    'path': file_path,\n",
    "                    'extension': extension,\n",
    "                    'content': f.read(),\n",
    "                })\n",
    "            print(f\"Chargé : {files[i]['name']} ({len(files[i]['content'])} caractères) {files[i]['extension']})\")\n",
    "    return files\n",
    "\n",
    "# Convert PDF to TXT\n",
    "def pdf_to_txt(file, output_folder_path):\n",
    "    \"\"\"\n",
    "    Convert a PDF file (already loaded as a dict from file_loader) to TXT and save it in output_folder.\n",
    "    Returns the path to the TXT file.\n",
    "    \"\"\"\n",
    "    txt_name = os.path.splitext(file['name'])[0] + '.txt'\n",
    "    txt_path = os.path.join(output_folder_path, txt_name)\n",
    "    if file['extension'] == '.pdf':\n",
    "        if not os.path.isfile(txt_path):\n",
    "            print(f\"Conversion du PDF {file['name']} en TXT...\")\n",
    "            with open(file['path'], 'rb') as f:\n",
    "                reader = PdfReader(f)\n",
    "                text = \"\"\n",
    "                for page in reader.pages:\n",
    "                    text += page.extract_text() or \"\"\n",
    "            with open(txt_path, 'w', encoding='utf-8') as f_txt:\n",
    "                f_txt.write(text)\n",
    "            print(f\"Fichier TXT créé : {os.path.splitext(file['name'])[0]}.txt\")\n",
    "        else:\n",
    "            print(f\"Le fichier TXT {txt_name} existe déjà, pas de conversion nécessaire.\")\n",
    "        return txt_path\n",
    "    print(f\"Le fichier {file['name']} n'est pas un PDF, pas de conversion effectuée.\")\n",
    "    return None\n",
    "\n",
    "sources_path = os.path.join(os.getcwd(), \"sources\")\n",
    "transformed_sources_path = os.path.join(os.getcwd(), \"transformed_sources\")\n",
    "files = file_loader(sources_path)\n",
    "for file in files:\n",
    "    if(file['extension'] == '.pdf'):\n",
    "        pdf_to_txt(file, transformed_sources_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9017fc49",
   "metadata": {},
   "source": [
    "# Découpage des fichiers txt en chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af218f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les fichiers suivants ne sont plus présents : ['truc.txt', 'chose.txt']\n",
      "2 fichiers de chunks ont été supprimés (dans 'chunks/CS_500_CO_50'/).\n",
      "Aucun nouveaux fichier n'a été détecté (dans 'transformed_sources/').\n",
      "0 fichiers ont été découpés en chunks (dans 'chunks/CS_500_CO_50/').\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "import tiktoken\n",
    "import json\n",
    "\n",
    "# Paramètres des chunks\n",
    "SOURCES_DIR = \"transformed_sources\"                             # Dossier contenant les fichiers texte à découper\n",
    "CHUNK_SIZE = 300                                                # Nombre de tokens par chunk\n",
    "CHUNK_OVERLAP = 30                                              # Nombre de tokens de chevauchement\n",
    "OUTPUT_DIR = f\"chunks/CS_{CHUNK_SIZE}_CO_{CHUNK_OVERLAP}\"       # Dossier de sortie pour les chunks\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")     # Utiliser l'encodeur de tokens de OpenAI (compatible Mistral)\n",
    "\n",
    "# Initialiser le découpeur de texte\n",
    "splitter = TokenTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    encoding_name=\"cl100k_base\",\n",
    ")\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def write_json(path, config):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(config, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "def chunk_files(new_files, old_files):\n",
    "    i = 0\n",
    "    for i, new_file in enumerate(new_files, start=1):\n",
    "        print(f\"Découpage de {new_file} en chunk de {CHUNK_SIZE} tokens...\")\n",
    "        chunk_file(os.path.join(SOURCES_DIR, new_file))\n",
    "\n",
    "    print(f\"{i} fichiers ont été découpés en chunks (dans '{OUTPUT_DIR}/').\")\n",
    "    new_param = {\n",
    "        \"CHUNK_SIZE\": CHUNK_SIZE,\n",
    "        \"CHUNK_OVERLAP\": CHUNK_OVERLAP,\n",
    "        \"SOURCE_DIR\": SOURCES_DIR,\n",
    "        \"files\": old_files + new_files,\n",
    "    }\n",
    "    write_json(os.path.join(OUTPUT_DIR, \"param.json\"), new_param)\n",
    "\n",
    "\n",
    "def chunk_file(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    chunks = splitter.split_text(text)\n",
    "\n",
    "    filename = os.path.splitext(os.path.basename(filepath))[0]\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        with open(os.path.join(OUTPUT_DIR, f\"{filename}_chunk_{i}.txt\"), \"w\", encoding=\"utf-8\") as out:\n",
    "            out.write(chunk)\n",
    "\n",
    "def chunk_cleaner(files):\n",
    "    param = read_json(os.path.join(OUTPUT_DIR, \"param.json\"))\n",
    "\n",
    "    p_chunk_size = param.get(\"CHUNK_SIZE\")\n",
    "    p_chunk_overlap = param.get(\"CHUNK_OVERLAP\")\n",
    "    p_sources_dir = param.get(\"SOURCE_DIR\")\n",
    "    p_files = param.get(\"files\")\n",
    "\n",
    "    if p_chunk_size == CHUNK_SIZE and p_chunk_overlap == CHUNK_OVERLAP and p_sources_dir == SOURCES_DIR:\n",
    "        removed_files = list(set(p_files) - set(files))\n",
    "        new_files = list(set(files) - set(p_files))\n",
    "        if removed_files:\n",
    "            print(f\"Les fichiers suivants ne sont plus présents : {removed_files}\")\n",
    "            nb_cleaned = chunk_eraser(removed_files)\n",
    "            print(f\"{nb_cleaned} fichiers de chunks ont été supprimés (dans '{OUTPUT_DIR}'/).\")\n",
    "            param[\"files\"] = [f for f in p_files if f not in removed_files]\n",
    "            write_json(os.path.join(OUTPUT_DIR, \"param.json\"), param)\n",
    "        if not new_files:\n",
    "            print(f\"Aucun nouveaux fichier n'a été détecté (dans '{SOURCES_DIR}/').\")\n",
    "        else:\n",
    "            print(f\"{len(new_files)} nouveaux fichiers ont été détectés : {new_files} (dans '{SOURCES_DIR}/').\")\n",
    "        return new_files, param[\"files\"]\n",
    "\n",
    "def chunk_eraser(diff):\n",
    "    nb_cleaned = 0\n",
    "    for file in diff:\n",
    "        prefix = os.path.splitext(file)[0]\n",
    "        for f in os.listdir(OUTPUT_DIR):\n",
    "            if f.startswith(prefix) and f.endswith(\".txt\"):\n",
    "                file_path = os.path.join(OUTPUT_DIR, f)\n",
    "                if os.path.isfile(file_path):\n",
    "                    os.remove(file_path)\n",
    "                    nb_cleaned += 1\n",
    "    return nb_cleaned\n",
    "\n",
    "files = [f for f in os.listdir(SOURCES_DIR) if f.endswith(\".txt\")]\n",
    "old_files = []\n",
    "if os.path.isfile(os.path.join(OUTPUT_DIR, \"param.json\")):\n",
    "    files, old_files = chunk_cleaner(files)\n",
    "else:\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "chunk_files(files, old_files)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db6c14",
   "metadata": {},
   "source": [
    "# Création de la base de données vectorielle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a40b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture des chunks...\n",
      "Génération des embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 48/48 [00:49<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion dans la base vectorielle...\n",
      "1506 chunks ajoutés à la base vectorielle dans 'vector_db'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "\n",
    "CHUNKS_DIR = \"chunks/CS_300_CO_30\"  # Dossier contenant les chunks\n",
    "VECTOR_DB_DIR = \"vector_db\"\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "# Init Chroma\n",
    "client = chromadb.PersistentClient(path=\"vector_db\")\n",
    "collection = client.get_or_create_collection(\"warhammer_collection\")\n",
    "\n",
    "# Embedding model\n",
    "model = SentenceTransformer(EMBEDDING_MODEL)\n",
    "\n",
    "# Lecture des chunks\n",
    "def load_chunks():\n",
    "    chunks = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "    for file in os.listdir(CHUNKS_DIR):\n",
    "        if file.endswith(\".txt\"):\n",
    "            path = os.path.join(CHUNKS_DIR, file)\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "                chunks.append(content)\n",
    "                metadatas.append({\"filename\": file})\n",
    "                ids.append(str(uuid.uuid4()))  # identifiant unique\n",
    "    return chunks, metadatas, ids\n",
    "\n",
    "# Génération + insertion\n",
    "def embed_and_store():\n",
    "    print(\"Lecture des chunks...\")\n",
    "    texts, metadatas, ids = load_chunks()\n",
    "\n",
    "    print(\"Génération des embeddings...\")\n",
    "    embeddings = model.encode(texts, show_progress_bar=True).tolist()\n",
    "\n",
    "    print(\"Insertion dans la base vectorielle...\")\n",
    "    collection.add(\n",
    "        documents=texts,\n",
    "        embeddings=embeddings,\n",
    "        metadatas=metadatas,\n",
    "        ids=ids\n",
    "    )\n",
    "\n",
    "    print(f\"{len(texts)} chunks ajoutés à la base vectorielle dans '{VECTOR_DB_DIR}'.\")\n",
    "\n",
    "embed_and_store()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d215ee5",
   "metadata": {},
   "source": [
    "# Test du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f20f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recherche des passages les plus pertinents...\n",
      "\n",
      "\n",
      "--- Résultat 1 (Warhammer 4 - Livre de base_chunk_139.txt) - Similarité : 11.17% ---\n",
      "• Pourchasser le tueur d'un membre décédé du groupe.\n",
      "• Impressionner votre commanditaire en réussissant\n",
      "complètement une tâche qui vous a été confiée.\n",
      "Ambitions à L ong Terme du Groupe \n",
      "Tout comme les Ambitions de groupe à court terme, \n",
      "les Ambitions  de groupe à long terme fonctionnent comme \n",
      "vos Ambitions personnelles, et peuvent avoir une portée tout \n",
      "aussi large, mais s'adressent à votre groupe tout entier.\n",
      "Voici des exemples d'ambitions à long terme pour le Groupe :\n",
      "• Éradiquer un culte du chaos à l'échelle de l'Empire.\n",
      "• Construisez un château.\n",
      "• Devenez des Héros de l'Empire, chacun d'eux recevant\n",
      "une Croix Impériale pour bravoure, épinglée sur vos\n",
      "poitrines par l'Empereur lui-même !\n",
      "Réaliser les  Ambitions de  Votre Groupe\n",
      "Si votre groupe atteint son Ambition à court terme, \n",
      "chaque membre reçoit +50 XP, et vous pouvez tous choisir une \n",
      "nouvelle Ambition pour le groupe à la fin de la session. \n",
      "Si votre groupe réalise son ambition à long terme :\n",
      "• Tous les joueurs reçoivent un bo\n",
      "\n",
      "--- Résultat 2 (Warhammer 4 - Livre de base_chunk_35.txt) - Similarité : 5.79% ---\n",
      "la \n",
      "marine impériale et démontre ouvertement la confiance et la puissance militaire croissantes du \n",
      "Wasteland. Les villes et villages puissants et impressionnants de l'Empire prospère sont les joyaux de la couronne du royaume de \n",
      "Sa Majesté impériale l'empereur Karl-Franz Ier. Riches, cultivés, pieux, éduqués et prospères, leur planification \n",
      "extraordinaire de L'architecture inspirante fait l'envie de tous et attire des voyageurs aux yeux écarquillés venus des \n",
      "quatre coins du monde pour en admirer la magnificence. Sous le règne nourricier de Sa Majesté impériale l'empereur \n",
      "Karl-Franz Ier, chacun de ses innombrables sujets a la possibilité de s'améliorer et de s'élever vers de nouveaux postes \n",
      "élevés. Même les gens simples de l'Empire, malgré leur apparence modeste et souvent dégoûtante, sont travailleurs et \n",
      "optimistes, toujours à la recherche de nouvelles opportunités pour le bienfait de tous.\n",
      "Les principales colonies de peuplement de l'Empire peuvent présenter certaines des \n",
      "archit\n",
      "\n",
      "--- Résultat 3 (Warhammer 4 - Livre de base_chunk_62.txt) - Similarité : 5.39% ---\n",
      "et le plus puissant est l'Empire, \n",
      "un patchwork de provinces puissantes recouvertes de forêts \n",
      "apparemment infinies. Fier d'être au cœur de cet Empire, le \n",
      "Reikland est sa région la plus riche et la plus cosmopolite.\n",
      "De nombreux Reiklanders y voient leur droit divin de régner, \n",
      "car le dieu-patron de l'Empire, Sigmar, était lui-même un \n",
      "Reiklander avant son ascension vers la divinité il y a plusieurs \n",
      "siècles. On trouve partout des temples et des sanctuaires du \n",
      "dieu, et la majorité des Reiklanders croient fermement au \n",
      "discours de Sigmar sur l'Empire et sur l'unité. Pour cette raison, \n",
      "ils sont beaucoup plus amicaux, ouverts et optimistes que les \n",
      "autres, car qu'est-ce qui pourrait mal tourner pour une terre qui \n",
      "a donné naissance à un dieu ? En comparaison, les étrangers les \n",
      "voient souvent comme des fouineurs arrogants et trop \n",
      "péremptoires qui mettent leur nez non désiré dans une de leurs \n",
      "affaires.\n",
      "Au-delà de leur mode de vie aisé et de leur personnalité \n",
      "arrogante, les Reiklanders\n",
      "\n",
      "--- Résultat 4 (Warhammer 4 - Livre de base_chunk_53.txt) - Similarité : 3.19% ---\n",
      ", ce qui les rend relativement surs. L'Empire est aussi beaucoup plus civilisé \n",
      "~~Patrouilles\n",
      "Conscients de la menace que representent les bandits de grand chemin, tous les grands axes routiers du Reikland sont patrouilles par des \n",
      "escadrons de sentinelles de la route. La plupart sont des cavaliers de l'armee d'Etat en temps de paix mis à contribution par des nobles locaux, \n",
      "mais certains sont engages à titre prive, souvent par des marchands ou des compagnies de diligence, pour mieux assurer la paix et proteger les \n",
      "biens couteux. Quand on s'eloigne des routes commerciales principales, les routes ne sont pas aussi bien entretenues, et certains ont de la chance de \n",
      "voir un garde routier, alors je suggere d'eviter ces coins sombres de l'Empire, car les gens du pays sont souvent... agressive pour vous prendre tous \n",
      "vos objets, et peut-être même votre vie.. Les rivieres font l'objet de patrouilles similaires, mais sont surveillées par des navires arme à bord de divers \n",
      "types de navires, al\n",
      "\n",
      "--- Résultat 5 (Warhammer 4 - Livre de base_chunk_1226.txt) - Similarité : 0.99% ---\n",
      "ges, pour ne \n",
      "jamais revenir.\n",
      "2420-2424 Ic\n",
      "WAAAGH ! Grom ! Le Gobelin Warboss \n",
      "Grom la bedaine mène une énorme horde \n",
      "de Peaux-Vertes à travers l'Empire, \n",
      "saccageant plusieurs villes et villages du \n",
      "Reikland, avant de se diriger vers l'ouest, \n",
      "invaincu, où il prend ensuite la mer. Le \n",
      "manque de magistères dans les collèges de \n",
      "magie suspendus est largement blâmé pour \n",
      "les défaites militaires répétées subies par les \n",
      "armées du Reikland.\n",
      "2429 Ic\n",
      "Westerland achète son indépendance de \n",
      "l'Empire en soudoyant l'empereur Dieter IV, \n",
      "en se réformant en tant que désert avec \n",
      "Marienburg comme capitale. Utilisant les \n",
      "lois anti-corruption mises en place par \n",
      "Magnus le Pieux presque cent ans plus tôt, \n",
      "les électeurs comptent destituer Dieter dans le \n",
      "scandale qui en résulta. Il est remplacé par \n",
      "le Grand Prince Wilhelm de la Maison \n",
      "Holswig-Schliestein du Reikland, qui est \n",
      "nommé Empereur Wilhelm III, à sa \n",
      "succession à la\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Configuration\n",
    "VECTOR_DB_DIR = \"vector_db\"\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "TOP_K = 5  # nombre de résultats à retourner\n",
    "\n",
    "# Initialisation du client et du modèle\n",
    "client = chromadb.PersistentClient(path=VECTOR_DB_DIR)\n",
    "collection = client.get_collection(\"warhammer_collection\")\n",
    "model = SentenceTransformer(EMBEDDING_MODEL)\n",
    "\n",
    "def ask_question():\n",
    "    # question = input(\"Pose ta question : \").strip()\n",
    "    # if not question:\n",
    "    #     print(\"Tu dois poser une question.\")\n",
    "    #     return\n",
    "    question = \"Quel est la capitale de l'Empire ?\"\n",
    "\n",
    "    print(\"Recherche des passages les plus pertinents...\\n\")\n",
    "\n",
    "    # Embedding de la question\n",
    "    query_embedding = model.encode([question])[0].tolist()\n",
    "\n",
    "    # Recherche vectorielle\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=TOP_K,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "    )\n",
    "\n",
    "    # Affichage des résultats       \n",
    "    for i, (doc, meta, dist) in enumerate(zip(results[\"documents\"][0], results[\"metadatas\"][0], results[\"distances\"][0])):\n",
    "        print(f\"\\n--- Résultat {i+1} ({meta['filename']}) - Similarité : {round((1 - dist) * 100, 2)}% ---\")\n",
    "        print(doc.strip()[:1000])\n",
    "        \n",
    "ask_question()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM1)",
   "language": "python",
   "name": "llm1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
