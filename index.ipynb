{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7dcb96",
   "metadata": {},
   "source": [
    "# Chargement des fichiers sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afa08c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargé : Warhammer 4 - Livre de base.pdf (67641992 caractères) .pdf)\n",
      "Conversion du PDF Warhammer 4 - Livre de base.pdf en TXT...\n",
      "Fichier TXT créé : Warhammer 4 - Livre de base.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Import Files \n",
    "def file_loader(folder):\n",
    "    files = []\n",
    "    for i, file_name in enumerate(os.listdir(folder)):\n",
    "        file_path = os.path.join(folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            extension = os.path.splitext(file_name)[1].lower()\n",
    "            with open(file_path, 'r', encoding='latin-1') as f:\n",
    "                files.append({\n",
    "                    'name': file_name,\n",
    "                    'path': file_path,\n",
    "                    'extension': extension,\n",
    "                    'content': f.read(),\n",
    "                })\n",
    "            print(f\"Chargé : {files[i]['name']} ({len(files[i]['content'])} caractères) {files[i]['extension']})\")\n",
    "    return files\n",
    "\n",
    "# Convert PDF to TXT\n",
    "def pdf_to_txt(file, output_folder_path):\n",
    "    \"\"\"\n",
    "    Convert a PDF file (already loaded as a dict from file_loader) to TXT and save it in output_folder.\n",
    "    Returns the path to the TXT file.\n",
    "    \"\"\"\n",
    "    txt_name = os.path.splitext(file['name'])[0] + '.txt'\n",
    "    txt_path = os.path.join(output_folder_path, txt_name)\n",
    "    if file['extension'] == '.pdf':\n",
    "        if not os.path.isfile(txt_path):\n",
    "            print(f\"Conversion du PDF {file['name']} en TXT...\")\n",
    "            with open(file['path'], 'rb') as f:\n",
    "                reader = PdfReader(f)\n",
    "                text = \"\"\n",
    "                for page in reader.pages:\n",
    "                    text += page.extract_text() or \"\"\n",
    "            with open(txt_path, 'w', encoding='utf-8') as f_txt:\n",
    "                f_txt.write(text)\n",
    "            print(f\"Fichier TXT créé : {os.path.splitext(file['name'])[0]}.txt\")\n",
    "        else:\n",
    "            print(f\"Le fichier TXT {txt_name} existe déjà, pas de conversion nécessaire.\")\n",
    "        return txt_path\n",
    "    print(f\"Le fichier {file['name']} n'est pas un PDF, pas de conversion effectuée.\")\n",
    "    return None\n",
    "\n",
    "sources_path = os.path.join(os.getcwd(), \"sources\")\n",
    "transformed_sources_path = os.path.join(os.getcwd(), \"transformed_sources\")\n",
    "files = file_loader(sources_path)\n",
    "for file in files:\n",
    "    if(file['extension'] == '.pdf'):\n",
    "        pdf_to_txt(file, transformed_sources_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9017fc49",
   "metadata": {},
   "source": [
    "# Découpage des fichiers txt en chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af218f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les fichiers suivants ne sont plus présents : ['truc.txt', 'chose.txt']\n",
      "2 fichiers de chunks ont été supprimés (dans 'chunks/CS_500_CO_50'/).\n",
      "Aucun nouveaux fichier n'a été détecté (dans 'transformed_sources/').\n",
      "0 fichiers ont été découpés en chunks (dans 'chunks/CS_500_CO_50/').\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "import tiktoken\n",
    "import json\n",
    "\n",
    "# Paramètres des chunks\n",
    "SOURCES_DIR = \"transformed_sources\"                             # Dossier contenant les fichiers texte à découper\n",
    "CHUNK_SIZE = 300                                                # Nombre de tokens par chunk\n",
    "CHUNK_OVERLAP = 30                                              # Nombre de tokens de chevauchement\n",
    "OUTPUT_DIR = f\"chunks/CS_{CHUNK_SIZE}_CO_{CHUNK_OVERLAP}\"       # Dossier de sortie pour les chunks\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")     # Utiliser l'encodeur de tokens de OpenAI (compatible Mistral)\n",
    "\n",
    "# Initialiser le découpeur de texte\n",
    "splitter = TokenTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    encoding_name=\"cl100k_base\",\n",
    ")\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def write_json(path, config):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(config, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "def chunk_files(new_files, old_files):\n",
    "    i = 0\n",
    "    for i, new_file in enumerate(new_files, start=1):\n",
    "        print(f\"Découpage de {new_file} en chunk de {CHUNK_SIZE} tokens...\")\n",
    "        chunk_file(os.path.join(SOURCES_DIR, new_file))\n",
    "\n",
    "    print(f\"{i} fichiers ont été découpés en chunks (dans '{OUTPUT_DIR}/').\")\n",
    "    new_param = {\n",
    "        \"CHUNK_SIZE\": CHUNK_SIZE,\n",
    "        \"CHUNK_OVERLAP\": CHUNK_OVERLAP,\n",
    "        \"SOURCE_DIR\": SOURCES_DIR,\n",
    "        \"files\": old_files + new_files,\n",
    "    }\n",
    "    write_json(os.path.join(OUTPUT_DIR, \"param.json\"), new_param)\n",
    "\n",
    "\n",
    "def chunk_file(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    chunks = splitter.split_text(text)\n",
    "\n",
    "    filename = os.path.splitext(os.path.basename(filepath))[0]\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        with open(os.path.join(OUTPUT_DIR, f\"{filename}_chunk_{i}.txt\"), \"w\", encoding=\"utf-8\") as out:\n",
    "            out.write(chunk)\n",
    "\n",
    "def chunk_cleaner(files):\n",
    "    param = read_json(os.path.join(OUTPUT_DIR, \"param.json\"))\n",
    "\n",
    "    p_chunk_size = param.get(\"CHUNK_SIZE\")\n",
    "    p_chunk_overlap = param.get(\"CHUNK_OVERLAP\")\n",
    "    p_sources_dir = param.get(\"SOURCE_DIR\")\n",
    "    p_files = param.get(\"files\")\n",
    "\n",
    "    if p_chunk_size == CHUNK_SIZE and p_chunk_overlap == CHUNK_OVERLAP and p_sources_dir == SOURCES_DIR:\n",
    "        removed_files = list(set(p_files) - set(files))\n",
    "        new_files = list(set(files) - set(p_files))\n",
    "        if removed_files:\n",
    "            print(f\"Les fichiers suivants ne sont plus présents : {removed_files}\")\n",
    "            nb_cleaned = chunk_eraser(removed_files)\n",
    "            print(f\"{nb_cleaned} fichiers de chunks ont été supprimés (dans '{OUTPUT_DIR}'/).\")\n",
    "            param[\"files\"] = [f for f in p_files if f not in removed_files]\n",
    "            write_json(os.path.join(OUTPUT_DIR, \"param.json\"), param)\n",
    "        if not new_files:\n",
    "            print(f\"Aucun nouveaux fichier n'a été détecté (dans '{SOURCES_DIR}/').\")\n",
    "        else:\n",
    "            print(f\"{len(new_files)} nouveaux fichiers ont été détectés : {new_files} (dans '{SOURCES_DIR}/').\")\n",
    "        return new_files, param[\"files\"]\n",
    "\n",
    "def chunk_eraser(diff):\n",
    "    nb_cleaned = 0\n",
    "    for file in diff:\n",
    "        prefix = os.path.splitext(file)[0]\n",
    "        for f in os.listdir(OUTPUT_DIR):\n",
    "            if f.startswith(prefix) and f.endswith(\".txt\"):\n",
    "                file_path = os.path.join(OUTPUT_DIR, f)\n",
    "                if os.path.isfile(file_path):\n",
    "                    os.remove(file_path)\n",
    "                    nb_cleaned += 1\n",
    "    return nb_cleaned\n",
    "\n",
    "files = [f for f in os.listdir(SOURCES_DIR) if f.endswith(\".txt\")]\n",
    "old_files = []\n",
    "if os.path.isfile(os.path.join(OUTPUT_DIR, \"param.json\")):\n",
    "    files, old_files = chunk_cleaner(files)\n",
    "else:\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "chunk_files(files, old_files)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db6c14",
   "metadata": {},
   "source": [
    "# Création de la base de données vectorielle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a40b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timot\\anaconda3\\envs\\LLM1\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture des chunks...\n",
      "Génération des embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 48/48 [00:46<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion dans la base vectorielle...\n",
      "1506 chunks ajoutés à la base vectorielle dans 'vector_db'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "\n",
    "CHUNKS_DIR = \"chunks\"\n",
    "VECTOR_DB_DIR = \"vector_db\"\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "# Init Chroma\n",
    "client = chromadb.PersistentClient(path=\"vector_db\")\n",
    "client.reset()  # Réinitialiser la base de données\n",
    "collection = client.get_or_create_collection(\"warhammer_collection\")\n",
    "\n",
    "# Embedding model\n",
    "model = SentenceTransformer(EMBEDDING_MODEL)\n",
    "\n",
    "# Lecture des chunks\n",
    "def load_chunks():\n",
    "    chunks = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "    for file in os.listdir(CHUNKS_DIR):\n",
    "        if file.endswith(\".txt\"):\n",
    "            path = os.path.join(CHUNKS_DIR, file)\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "                chunks.append(content)\n",
    "                metadatas.append({\"filename\": file})\n",
    "                ids.append(str(uuid.uuid4()))  # identifiant unique\n",
    "    return chunks, metadatas, ids\n",
    "\n",
    "# Génération + insertion\n",
    "def embed_and_store():\n",
    "    print(\"Lecture des chunks...\")\n",
    "    texts, metadatas, ids = load_chunks()\n",
    "\n",
    "    print(\"Génération des embeddings...\")\n",
    "    embeddings = model.encode(texts, show_progress_bar=True).tolist()\n",
    "\n",
    "    print(\"Insertion dans la base vectorielle...\")\n",
    "    collection.add(\n",
    "        documents=texts,\n",
    "        embeddings=embeddings,\n",
    "        metadatas=metadatas,\n",
    "        ids=ids\n",
    "    )\n",
    "\n",
    "    print(f\"{len(texts)} chunks ajoutés à la base vectorielle dans '{VECTOR_DB_DIR}'.\")\n",
    "\n",
    "embed_and_store()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d215ee5",
   "metadata": {},
   "source": [
    "# Test du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59f20f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recherche des passages les plus pertinents...\n",
      "\n",
      "\n",
      "--- Résultat 1 (Warhammer 4 - Livre de base_chunk_429.txt) - Similarité : 23.56% ---\n",
      ", bon \n",
      "nombre d'entre eux bénéficie de longues périodes de congé. Les \n",
      "officiers des armées d'État peuvent également commander de petites \n",
      "bandes de soldats pour enquêter sur des événements inhabituels dans \n",
      "le \" territoire \" de leur régiment et certains officiers considèrent ce \n",
      "genre d'aventures comme un excellent entraînement pour garder \n",
      "leurs soldats en forme. Les soldats non-humains seront souvent en \n",
      "mission dans l'Empire qui est des aventures de par leur nature \n",
      "même.\n",
      "III\n",
      "115CLASSE ET CARRIERE - GUERRIER\n",
      "CHEMIN DE CARRIERE\n",
      "h    Recrue — Argent 1\n",
      "Compétences: Athlétisme, Escalade, Calme, Esquive,   \n",
      "(tambour ou fifre)Résistance, Langue (combat), Mêlée (de \n",
      "base) , Jouer  \n",
      "Talents: Joueur de Dés, Bon Tireur, Dos Solide, Guerrier Né \n",
      "Objets: Dague, Plastron en Cuir \n",
      "Poli, Uniforme\n",
      "    Soldat — Argent 3\n",
      "Compétences:  Résistance a l'alcool, Jeux, Commérages, \n",
      "Mêlée (choix), à Distance (choix), Survie en Ext\n",
      "\n",
      "--- Résultat 2 (Warhammer 4 - Livre de base_chunk_428.txt) - Similarité : 7.78% ---\n",
      "y a beaucoup d'autres soldats, comme les \n",
      "mercenaires, les milices locales (qui sont rarement meilleures \n",
      "que les recrues), les armées privées, les forces sectaires, et plus \n",
      "encore. \n",
      "AVANCEMEMENT  SOLDAT\n",
      "CCCT FEIAgiDex IntFM Soc\n",
      "h h h‘ Descendre en bas de la colline, nous a dit le capitaine. C'est ce \n",
      "que nous avons fait, et le général nous a dit d'aller au sommet \n",
      "de la colline et d'attendre d'autres ordres. Puis le capitaine nous a \n",
      "dit qu'on nous attendait en bas.\n",
      "– Holger Kass, 1st Bögenhafen Halberdiers\n",
      "Bien que les Seigneurs et les Dames vont et viennent, la vie d'un soldat \n",
      "est tout ce que je sais,Karl-Franz commande, et nous obéissons, Sur les \n",
      "collines et au loin. \n",
      "– Marching Song, Reikland 118th Regiment of Foot,\n",
      "‘The Greenbacks’\n",
      "Les soldats ont peu de temps libre, mais ils ont encore des occasions \n",
      "d'aventure. En dehors de la saison de la campagne électorale, bon \n",
      "nombre d'entre eux bénéficie de longues périodes de congé. Les \n",
      "officiers des armées d'\n",
      "\n",
      "--- Résultat 3 (Warhammer 4 - Livre de base_chunk_427.txt) - Similarité : 1.37% ---\n",
      ", lorsque le \n",
      "besoin s'en fait sentir, aller à la guerre.\n",
      "Sous le commandement de l'empereur Magnus le Pieux \n",
      "après la Grande Guerre contre le Chaos, toutes les provinces de \n",
      "l'Empire ont dû maintenir une armée d'Etat permanente. Les \n",
      "soldats sont le pilier de ces armées, entraînées à combattre dans le \n",
      "cadre d'un groupe plus large, avec des compétences individuelles \n",
      "complétées par la force du nombre. Rarement encouragés à \n",
      "penser par eux-mêmes, les soldats sont réputés pour leur \n",
      "fatalisme stoïque puisqu'ils sont commandés de colonne en \n",
      "poste, au service de leurs supérieurs. Les soldats peuvent être \n",
      "des archers, des arbalétriers, des hallebardiers, des \n",
      "mitrailleurs, des épéistes ou des lanciers, et c'est tout \n",
      "simplement dans un régiment typique d'États. Les nains \n",
      "emploient des soldats comme les Marteleurs et les Fusiliers, tandis \n",
      "que les elfes de base sont habituellement des archers et des \n",
      "lanciers. Il y a beaucoup d'autres soldats, comme les \n",
      "mercenaires, les milices locales \n",
      "\n",
      "--- Résultat 4 (Warhammer 4 - Livre de base_chunk_182.txt) - Similarité : 0.33% ---\n",
      "pendant que ses \n",
      "camarades cherchent dans une bibliothèque des informations qu'il \n",
      "ne comprend pas, et pense en secret qu'il pourrait être hérétique si \n",
      "tel était le cas. Le MJ accepte de laisser Gunther ce faire des \n",
      "revenus, donc Gunther jette un dé contre sa compétence de \n",
      "Conduite (Entraîneur) (sa compétence de Rémunération pour le \n",
      "Cocher) et il réussi. Étant donné que son statut est Argent 2, il \n",
      "peut lancer 2d10 et gagner autant d'argent. Malheureusement, il \n",
      "obtient que un 1 et un 2 pour un total de 3 pistole d'argent en \n",
      "tout. Gunther buvait beaucoup après ses longs quarts de travail, et \n",
      "il lui reste peu de pièces....\n",
      "LES NOMS DE CARRIÈRE SELON LE \n",
      "SEXE\n",
      "Bien que certaines carrières portent des noms masculins ou \n",
      "féminins en raison des limites de la langue, toutes les carrières \n",
      "sont destinées à n'importe quel sexe ; ainsi, peu importe \n",
      "comment votre personnage s'identifie, toutes les carrières \n",
      "lui sont disponibles.\n",
      "Par exemple : N'importe qui peut servir n'importe quelle div\n",
      "\n",
      "--- Résultat 5 (Warhammer 4 - Livre de base_chunk_94.txt) - Similarité : -3.1% ---\n",
      ", mais certains ont des opportunités \n",
      "qui peuvent mener à une vie très confortable. \n",
      "Options de carrière : Batelier, Pilote Patrouilleur fluvial, \n",
      "Riveraine, Matelot, Contrebandier, Débardeur, Naufrageur.\n",
      "Filous : principalement citadins, ces gens gagnent leur vie par \n",
      "des actes considérés comme illégaux, ou du moins peu \n",
      "recommandables, par la plupart des citoyens respectueux des \n",
      "lois. \n",
      "Options de carrière :  trafiquant, Charlatan, Receleur, \n",
      "Pilleur de tombe, Hors-la-loi, voleur, racketteur, sorcière.\n",
      "Guerriers : S'appuyant sur leurs prouesses physiques, ces \n",
      "personnes sont toutes des combattants entraînés, bien qu'elles ne \n",
      "soient pas nécessairement des militaires. Les guerriers viennent \n",
      "de différents milieux, de haut et de bas statut, et tous peuvent se \n",
      "tailler une position d'influence s'ils vivent assez longtemps. \n",
      "Options de carrière : cavalier, Garde, Chevalier, Gladiateur, \n",
      "Gros Bras, Soldat, Tueur de Troll, Prêtre guerrier\n",
      "CARRIÈRE\n",
      "Résumé : Choisis\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Configuration\n",
    "VECTOR_DB_DIR = \"vector_db\"\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "TOP_K = 5  # nombre de résultats à retourner\n",
    "\n",
    "# Initialisation du client et du modèle\n",
    "client = chromadb.PersistentClient(path=VECTOR_DB_DIR)\n",
    "collection = client.get_collection(\"docs\")\n",
    "model = SentenceTransformer(EMBEDDING_MODEL)\n",
    "\n",
    "def ask_question():\n",
    "    question = input(\"Pose ta question : \").strip()\n",
    "    if not question:\n",
    "        print(\"Tu dois poser une question.\")\n",
    "        return\n",
    "\n",
    "    print(\"Recherche des passages les plus pertinents...\\n\")\n",
    "\n",
    "    # Embedding de la question\n",
    "    query_embedding = model.encode([question])[0].tolist()\n",
    "\n",
    "    # Recherche vectorielle\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=TOP_K,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "    )\n",
    "\n",
    "    # Affichage des résultats       \n",
    "    for i, (doc, meta, dist) in enumerate(zip(results[\"documents\"][0], results[\"metadatas\"][0], results[\"distances\"][0])):\n",
    "        print(f\"\\n--- Résultat {i+1} ({meta['filename']}) - Similarité : {round((1 - dist) * 100, 2)}% ---\")\n",
    "        print(doc.strip()[:1000])\n",
    "        \n",
    "ask_question()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM1)",
   "language": "python",
   "name": "llm1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
